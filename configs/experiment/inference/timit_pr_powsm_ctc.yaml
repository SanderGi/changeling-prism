# @package _global_

defaults:
  - override /model: phone_recognition # do not matter, only to satisfy requirement
  - override /model/net: powsm_ctc
  - override /data: timit
  - override /logger: csv

task_name: "inf_timit_pr_powsm_ctc"
tags: ["inf_timit_pr_powsm_ctc"]

seed: 42

distributed_predict: True

data:
  tokenizer:
    _target_: src.core.ipa_utils.IPATokenizer
  mask_probability: 0.0

inference:
  num_workers: 15 # number of parallel workers for distributed inference
  passthrough_keys: ["phones", "utt_id", "split", "masked_phones"] # keys from dataset to be passed to output
  out_file: ${paths.output_dir}/timit_powsmctc_${data.mask_probability}.json
  # CTC inference runner
  inference_runner:
    _target_: src.model.powsm.powsm_ctc_inference.build_powsm_ctc_inference
    work_dir: ${paths.cache_dir}/powsm_ctc
    hf_repo: null
    force_download: False
    config_file: null
    model_file: null
    bpemodel: null
    stats_file: null
    device: cuda # auto, cpu, cuda
    dtype: float32
    # Long-form decoding settings
    max_segment_length: 30.0  # seconds
    context_len_in_secs: 2.0  # seconds  
    # Whether to use prompt encoder
    use_prompt_encoder: true
  # additional args to pass to the __call__ method of inference_runner, but can be overridden by keys from dataset
  inference_call_args: 
    text_prev: <na>
    lang_sym: <eng>
    task_sym: <pr>