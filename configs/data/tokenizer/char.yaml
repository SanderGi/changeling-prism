# Character-level tokenizer for IPA transcripts
# Requires vocab_path to be set (e.g., in experiment config or via CLI override)

# Example usage:
#   python src/main.py data/tokenizer=char

_target_: src.core.tokenizer.CharacterTokenizer

vocab_path: null

# Special token configuration (optional, defaults shown)
pad_token: "<pad>"
unk_token: "<unk>"