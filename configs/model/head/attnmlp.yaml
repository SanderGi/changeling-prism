# LinearHead configuration
# Reference: src/model/heads/attnmlp_head.py
_target_: src.model.heads.attnmlp_head.AttentionMLPHead
_partial_: true
# Required parameters (must be overridden)
input_dim: ???  # Encoder output dimension (e.g., 256 for powsm)
output_dim: ???  # Number of classes for classification
dropout: 0.0
# Task type: "classification" or "regression"
task_type: "classification"